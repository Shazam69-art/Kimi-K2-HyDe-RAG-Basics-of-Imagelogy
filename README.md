# Kimi-K2-HyDe-RAG-Basics-of-Imagelogy

Retrieval-Augmented Generation pipeline using Moonshot AI's **Kimi-k2** model with **Hypothetical Document Embeddings (HyDE)** approach  
for question answering on the official vocational radiology textbook:

**Basics of Imagelogy (S9) ‚Äì Paper III Theory, Standard XI**  
Directorate of Vocational Education and Training (DVET), Maharashtra

## Project Status (January 2025)

- ‚úÖ Complete offline pipeline: PDF extraction ‚Üí semantic chunking ‚Üí embedding generation  
- ‚öôÔ∏è Planned / in progress: HyDE-enhanced retrieval + Kimi-k2 generation stage  
- üì¶ Output files already production-ready: embeddings, metadata, summary report

## Important Disclaimer

**This project is created strictly for educational and research purposes only.**  
It is **not** a medical device, diagnostic tool, radiation safety reference, or substitute for professional training.  
Never use the answers generated by this system for clinical decisions, patient care, equipment operation, or regulatory compliance.  
Always consult qualified radiology professionals, certified instructors, and current official guidelines.

## Source Document

- Title: Basics of Imagelogy (S9) ‚Äì Paper III Theory, Standard XI  
- Publisher: Directorate of Vocational Education and Training, Maharashtra  
- Course: Radiology Technician (Vocational / NSQF aligned paramedical training)  
- Main topics covered:  
  - Radiation physics & production of X-rays  
  - Interaction of X-rays with matter  
  - Radiation protection & dosimetry  
  - Imaging with Ultrasonography  
  - Computed Tomography (CT)  
  - Magnetic Resonance Imaging (MRI)  
  - Nuclear Medicine & PET  
  - Interventional Radiology  
- Official PDF: https://www.dvet.gov.in/wp-content/uploads/2018/01/Directorate-of-Vocational-Education-Training_7.pdf

## Architecture Overview

### 1. Offline ‚Äì Knowledge Base Preparation (done)

- PDF text extraction ‚Üí PyPDF2 (page-aware)  
- Intelligent chunking ‚Üí ~450‚Äì550 words per chunk + 50-word overlap  
- Embedding model ‚Üí `BAAI/bge-base-en-v1.5` (768 dimensions, very strong retrieval performance)  
- Fallback mode ‚Üí TF-IDF (when transformers cannot be loaded)  
- Output files created:
Directorate-of-Vocational-Education-Training_7_embeddings.npy
Directorate-of-Vocational-Education-Training_7_metadata.pkl
Directorate-of-Vocational-Education-Training_7_vectorizer.pkl     (only if TF-IDF fallback)
Directorate-of-Vocational-Education-Training_7_summary.txt
text### 2. Online ‚Äì Retrieval + Generation (planned / to be implemented)

Typical flow will be:

1. User question  
2. Generate **hypothetical answer** using Kimi-k2 (HyDE step)  
3. Embed the hypothetical answer with bge-base-en-v1.5  
4. Retrieve top-k most similar real chunks from the textbook  
5. Build final context ‚Üí feed to Kimi-k2 again for reasoned, grounded answer  
6. Return answer + source references (page numbers + chunk excerpts)

## Requirements

```bash
Python 3.8 ‚Äì 3.11 recommended

pip install \
  PyPDF2 \
  sentence-transformers \
  numpy \
  torch \
  tqdm \
  pathlib
For inference stage (when you add it):
Bashpip install transformers accelerate
# Optional but recommended for faster retrieval:
pip install faiss-cpu    # or faiss-gpu
Very Important ‚Äì About Hugging Face Token
The current embedding generation code does NOT require any Hugging Face token.
However ‚Äî when you implement the inference part with Kimi-k2, you will need a Hugging Face access token because:

Kimi-k2 is a gated model on Hugging Face
You must accept the license on the model card first
Then generate a read token (fine-grained or classic)

How to use your own token safely:
Python# Recommended way ‚Äì never hardcode in repository!
from huggingface_hub import login
import os

# Best practice: use environment variable
login(token=os.getenv("HF_TOKEN"))

# OR during development (not for sharing):
# login(token="hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx")
Never commit your token to git!
Always use .env file + python-dotenv or environment variables.
Quick Start ‚Äì Generate Embeddings
Bash# 1. Update paths in the script if needed
# 2. Run:
python generate_embeddings.py
After successful run you should see:
textEmbeddings saved to: ..._embeddings.npy
Metadata saved to:   ..._metadata.pkl
Summary saved to:    ..._summary.txt
Next Steps ‚Äì Suggested Roadmap

Load embeddings + metadata
Implement query ‚Üí HyDE prompt ‚Üí Kimi-k2 hypothetical answer generation
Embed hypothesis ‚Üí retrieve top chunks
Final generation prompt with retrieved context
Add simple Gradio / Streamlit interface (highly recommended)
Add source citation rendering (page numbers + short excerpts)
Optional: add relevance threshold + fallback behavior

License
MIT License
Feel free to fork, modify, and use for your own educational/research projects.
Attribution appreciated but not required.
Acknowledgments

Moonshot AI ‚Äî Kimi-k2 model
BAAI ‚Äî bge-base-en-v1.5 (excellent open embedding model)
Directorate of Vocational Education and Training, Maharashtra ‚Äî open educational resource
Sentence Transformers team


Good luck with your vocational radiology RAG project!
If you run into any issues during implementation, feel free to open an issue.
